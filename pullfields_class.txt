# -*- coding: utf-8 -*-

import requests
import json
import math
import time
from datetime import datetime
import csv

auth_key = "x-api-key"
auth_value = "ak4vr6ocE2Ecgyc8bOt0PI2586b7e9cu1z6wRnhS"

headers = {auth_key: auth_value, "Accept": "application/json"}

working_folder = "C:/Users/lucy.schrader/Documents/Scripts/googleharvest/"
now = datetime.now()
current_time = now.strftime("%H-%M-%S")
output_csv = working_folder + current_time + "musarchives_titles.csv"
#all_irns_txt = working_folder + current_time + "all_irns.txt"
#deduped_irns_txt = working_folder + current_time + "deduped_irns.txt"

class CoApi():
    def __init__(self, headers=None, pagination_from=None, pagination_size=None):
        self.headers = headers
        self.pagination_from = pagination_from
        self.pagination_size = pagination_size

    def search(self):
        # To add: error handling and retrying
        request = Request(self.pagination_from, self.pagination_size)
        response = json.loads(requests.get(request.url, headers=self.headers).text)
        print("Requesting {}".format(request.url))
        return Results(response, request)

class Request():
#    def __init__(self, query=None, sort=None):
    def __init__(self, pagination_from, pagination_size):
        url_parts = []
        
        self.base_url = "https://data.tepapa.govt.nz/collection/search/"
        self.query = "&q=*"
        self.collection = " AND collection:MuseumArchives"
        self.types = " AND type:Object AND additionalType:PhysicalObject"
        self.downloadable = " AND hasRepresentation.rights.allowsDownload:true"
        self.sort = "&sort=id"
        self.pagination_from = pagination_from
        self.pagination_size = pagination_size

        url_parts.append("from={}&size={}".format(self.pagination_from, self.pagination_size))
        if self.sort:
            url_parts.append("{}".format(self.sort))
        if self.query:
            url_parts.append("{}".format(self.query))
        if self.collection:
            url_parts.append("{}".format(self.collection))
        if self.types:
            url_parts.append("{}".format(self.types))
        if self.downloadable:
            url_parts.append("{}".format(self.downloadable))
            
        self.url = self.buildUrl(url_parts)
        
    def buildUrl(self, url_parts=None):
        url = [
            self.base_url,
            "?",
            "".join(url_parts)
        ]
        return ''.join(url)

class Results():
    def __init__(self, response, request):
        self.request = request
        self.result_count = 0
        self.records = []

        self.result_count = response['_metadata']['resultset']['count']
        self.records = [result for result in response['results']]

class ApiRecord():
    def __init__(self, irn=None, record_type=None, record=None):
        self.irn = irn
        self.fields = {"IRN":self.irn}
        self.record_type = record_type
        self.record = record

    def add_data(self):
        self.get_combined_data()
#        self.get_object_data()
        
        self.fields.update({"CO_url":"https://collections.tepapa.govt.nz/object/{}".format(self.irn)})
#        print(self.fields)
        
        return self.fields

    def get_combined_data(self):
        pid = self.record["pid"]
        self.fields.update({"pid":pid})
#        print(self.fields)

        try:
            title = self.record["title"]
            title_length = str(len(title))
            self.fields.update({"title":title})
            self.fields.update({"title_length":title_length})
        except:
            self.fields.update({"title":"None"})
            self.fields.update({"title_length":"None"})
#        print(self.fields)

        try:
            description = self.record["description"]
            self.fields.update({"description":description})
        except: pass

        try:
            observedDimension = self.record["observedDimension"][0]["title"]
            self.fields.update({"observedDimension":observedDimension})
        except: pass

        images = self.record["hasRepresentation"]
        image_list_length = len(images)
        image_num = 0
        images_data_dict = {}
        for i in range(0,image_list_length):
            this_data_set = {}
            if images[image_num]:
                i_dat = images[image_num]
                image_irn = str(i_dat["id"])
                irn_dict = {"image_{}_irn".format(image_num):image_irn}
                this_data_set.update(irn_dict)
                image_type = i_dat["type"]
                image_url = i_dat["contentUrl"]
                image_rights = i_dat["rights"]["title"]
                try:
                    image_rights_url = i_dat["rights"]["iri"]
                except:
                    image_rights_url = ""
                if image_type == "ImageObject":
                    image_w = i_dat["width"]
                    image_h = i_dat["height"]
                else:
                    image_w = "n/a"
                    image_h = "n/a"

                this_data_set.update({"image_{}_type".format(image_num):image_type})
                this_data_set.update({"image_{}_url".format(image_num):image_url})
                this_data_set.update({"image_{}_rights".format(image_num):image_rights})
                this_data_set.update({"image_{}_rights_url".format(image_num):image_rights_url})
                this_data_set.update({"image_{}_w".format(image_num):image_w})
                this_data_set.update({"image_{}_h".format(image_num):image_h})

                images_data_dict.update({"image_{}".format(image_num): this_data_set})
            else: pass
#            print(images_data_dict)

            self.fields.update(images_data_dict)
#            print(self.fields)

            image_num += 1

    def get_object_data(self):
        if self.record['production']:
            prod_section = self.record['production']
            prod_list_length = len(prod_section)
            prod_num = 0
            prod_data_dict = {}
            for i in range(0,prod_list_length):
                prod_data_set = {}
                if prod_section[prod_num]:
                    p_dat = prod_section[prod_num]
                    prod_creator = p_dat["contributor"]["title"]
                    prod_role = p_dat["role"]
                    prod_date = p_dat["verbatimCreatedDate"]
                    if p_dat['spatial']:
                        prod_place = p_dat["spatial"]["title"]
                    else: prod_place = "n/a"

                    prod_data_set.update({"prod_creator_{}".format(prod_num):prod_creator}, {"prod_role_{}".format(prod_num):prod_role}, {"prod_date_{}".format(prod_num):prod_date}, {"prod_place_{}".format(prod_num):prod_place})

                    prod_data_dict.update({"prod_{}".format(prod_num):prod_data_set})
        else: pass

        try:
            prod_tech_section = self.record["productionUsedTechnique"]
            prod_tech = []
            prod_num = 0
            for prod_used in prod_tech_section[prod_num]:
                prod_tech.append(prod_used["title"])
                prod_num += 1

            self.fields.update({"productionUsedTechnique":str(prod_tech)})
        except: pass

        try:
            made_of = self.record["isMadeOfSummary"]
            self.fields.update({"isMadeOfSummary":made_of})
        except: pass

        try:
            made_of_section = self.record["isMadeOf"]
            made_of_cats = []
            made_num = 0
            for made_of in made_of_section[made_num]:
                made_cats.append(made_of["title"])
                made_num += 1

            self.fields.update({"made_of_cats":str(made_of_cats)})
        except: pass

        try:
            type_of_section = self.record["isTypeOf"]
            type_cats = []
            type_num = 0
            for type_of in type_of_section[type_num]:
                # poss run against whitelist and only select matches
                type_cats.append(type_of["title"])
                type_num += 1

            self.fields.update({"type_cats":str(type_cats)})
        except: pass

        try:
            influence_section = self.record["influencedBy"]
            inf_cats = []
            inf_num = 0
            for influencer in influence_section[inf_num]:
                inf_cats.append(influencer["title"])
                inf_num += 1

            self.fields.update({"influenced_by":str(inf_cats)})
        except: pass

        try:
            depicts_section = self.record["depicts"]
            depicts_cats = []
            dep_num = 0
            for depicted in depicts_section[dep_num]:
                depicts_cats.append(depicted["prefLabel"])
                dep_num += 1

            self.fields.update({"depicts":str(depicts_cats)})
        except: pass

        try:
            refers_section = self.record["refersTo"]
            refers_cats = []
            ref_num = 0
            for referent in refers_section[ref_num]:
                refers_cats.append(referent["prefLabel"])
                ref_num += 1

            self.fields.update({"refersTo":str(refers_cats)})
        except: pass

        try:
            credit_line = self.record["creditLine"]
            self.fields.update({"creditLine":credit_line})
        except: pass

# Might try and do this when I have all the fields figured out
'''
    def harvest_data_list(self, section_name, field_name):
        try:
            harvest_section = self.record[section_name]
            harvest_list = []
            harvest_num = 0
            for item in harvest_section[harvest_num]:
                harvest_list.append(item[field_name])
                harvest_num += 1

            self.fields.update({section_name:str(harvest_list)})

    def harvest_data_single(self, field_name):
        try:
            harvest_item = self.record[field_name]

            self.fields.update({field_name:harvest_item})
'''

# Okay now let's do the stuff
api_call = CoApi(headers=headers, pagination_from=0, pagination_size=10)

# Find out how many results there are and how many pages to query
count_response = api_call.search()
count = count_response.result_count
print(count)

per_page = 500
page_start = 0
page_count = math.ceil(count/per_page)

record_data_dict = {}

# Query each page to allow harvest
for i in range(0, page_count):
    page_call = CoApi(headers=headers, pagination_from = page_start, pagination_size = per_page)
    page_reponse = page_call.search()
    for record in page_reponse.records:
        try:
            irn = str(record["id"])
            record_type = record["type"]

            new_record = ApiRecord(irn=irn, record_type=record_type, record=record)

            new_data = new_record.add_data()

            record_data_dict.update({irn:new_data})
        except: pass

    page_start += per_page
    time.sleep(1)

all_irns = record_data_dict.keys()
#print(all_irns)

# Little test to see if we're writing to the dict
#print(record_data_dict)

csv_header = ["irn", "title", "title_length", "width", "height"]

with open(output_csv, 'w', newline='', encoding='utf-8') as f:

    writer = csv.writer(f, delimiter = ',')
    writer.writerow(csv_header)

    for irn in all_irns:
        no_of_images = 0
        for k in record_data_dict[irn].keys():
            if "image_" in k:
                no_of_images += 1
        for i in range(0,no_of_images):
            value_list = [irn]
            value_list.append(record_data_dict[irn]["title"])
            value_list.append(record_data_dict[irn]["title_length"])
            value_list.append(record_data_dict[irn]["image_{}".format(i)]["image_{}_w".format(i)])
            value_list.append(record_data_dict[irn]["image_{}".format(i)]["image_{}_h".format(i)])
            writer.writerow(value_list)
#            print(value_list)

f.close()